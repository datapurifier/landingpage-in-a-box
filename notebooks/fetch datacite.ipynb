{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works through the process of pulling metadata via the DataCite API and building content for the Hugo site. A more elegant solution might be to simply dump DataCite metadata in its original JSON form (possibly ld_json) and then run everything with templates that read data content. However, I've found that some amount of digesting that content into markdown files with YAML metadata works pretty well and provides some ready options. So, I'm trying not to overload this part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Eventually, I may need to run this as some type of automated process in a pipeline (e.g., in the GitHub actions to load site content before deploying). The following can be pulled out into a different type of pipeline environment for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for setting up the Hugo site\n",
    "def write_config(config, config_path='../hugo.yml'):\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False)\n",
    "    print(\"WROTE CONFIG FILE\")\n",
    "\n",
    "def datacite_repositories(documents):\n",
    "    repositories = [i['id'].split('/')[0] for i in documents]\n",
    "    return list(set(repositories))\n",
    "\n",
    "def build_sections(repositories, content_path='../content'):\n",
    "    for prefix in repositories:\n",
    "        folder_path = os.path.join(content_path, prefix)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        if not os.path.exists(os.path.join(folder_path, '_index.md')):\n",
    "            with open(os.path.join(folder_path, '_index.md'), 'w') as f:\n",
    "                f.write(f'---\\ntitle: {prefix}\\ndate: {str(datetime.utcnow().isoformat())}\\n---\\n')\n",
    "        print(\"SETUP FOLDER/FILE STRUCTURE FOR:\", prefix)\n",
    "\n",
    "def setup_taxonomy(layouts_folder, themes_folder, names):\n",
    "    for name in names:\n",
    "        folder_path = os.path.join(layouts_folder, name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        list_copy_path = os.path.join(folder_path, 'list.html')\n",
    "        terms_copy_path = os.path.join(folder_path, 'terms.html')\n",
    "        \n",
    "        list_source_path = os.path.join(themes_folder, 'list.html')\n",
    "        terms_source_path = os.path.join(themes_folder, 'terms.html')\n",
    "        \n",
    "        if not os.path.exists(list_copy_path):\n",
    "            shutil.copy(list_source_path, list_copy_path)\n",
    "        \n",
    "        if not os.path.exists(terms_copy_path):\n",
    "            shutil.copy(terms_source_path, terms_copy_path)\n",
    "        print(\"SETUP FOLDER/FILE STRUCTURE FOR:\", name)\n",
    "\n",
    "# Functions for building content items from DataCite documents\n",
    "def datacite_categories(doc):\n",
    "    categories = [doc['attributes']['types']['resourceTypeGeneral']]\n",
    "    return categories\n",
    "\n",
    "def datacite_tags(doc):\n",
    "    tags = []\n",
    "    for subject in doc['attributes']['subjects']:\n",
    "        if subject['subject']:\n",
    "            if ',' in subject['subject']:\n",
    "                tags.extend([i.strip() for i in subject['subject'].split(',')])\n",
    "            else:\n",
    "                tags.append(subject['subject'])\n",
    "    return tags\n",
    "\n",
    "def datacite_publishers(doc):\n",
    "    publishers = [doc['attributes']['publisher']]\n",
    "    return publishers\n",
    "\n",
    "def datacite_creators(doc):\n",
    "    authors = []\n",
    "    affiliations = []\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        if creator['affiliation']:\n",
    "            affiliations.extend(creator['affiliation'])\n",
    "        name_string = creator['name']\n",
    "        if creator['nameType'] == 'Personal' and 'givenName' in creator and 'familyName' in creator:\n",
    "            name_string = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "        authors.append(name_string)\n",
    "            \n",
    "    return authors, list(set(affiliations))\n",
    "\n",
    "def datacite_funders(doc):\n",
    "    funders = []\n",
    "    for funder in doc['attributes']['fundingReferences']:\n",
    "        if funder['funderName']:\n",
    "            funders.append(funder['funderName'])\n",
    "    return list(set(funders))\n",
    "\n",
    "def datacite_orcids(doc, orcid_mapping=[]):\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        orcid = next((i['nameIdentifier'].split('/')[-1] for i in creator['nameIdentifiers'] if i['nameIdentifierScheme'] == 'ORCID'), None)\n",
    "        if not orcid:\n",
    "            return orcid_mapping\n",
    "\n",
    "        name_string = creator['name']\n",
    "        if creator['nameType'] == 'Personal' and 'givenName' in creator and 'familyName' in creator:\n",
    "            name_string = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "        orcid_mapping.append((name_string, orcid))\n",
    "\n",
    "    return orcid_mapping\n",
    "\n",
    "def datacite_meta(doc):\n",
    "    meta_content = ['---']\n",
    "    title = doc['attributes']['titles'][0]['title']\n",
    "    meta_content.append(f'title: \"{title}\"')\n",
    "    meta_content.append(f\"doi: {doc['id']}\")\n",
    "    meta_content.append(f\"date: {doc['attributes']['updated']}\")\n",
    "    # meta_content.append(f\"date: {doc['attributes']['publicationYear']}\")\n",
    "    meta_content.append(f\"categories: {datacite_categories(doc)}\")\n",
    "    meta_content.append(f\"tags: {datacite_tags(doc)}\")\n",
    "    meta_content.append(f\"publishers: {datacite_publishers(doc)}\")\n",
    "    authors, affiliations = datacite_creators(doc)\n",
    "    if authors:\n",
    "        meta_content.append(f\"author: {authors}\")\n",
    "    if affiliations:\n",
    "        meta_content.append(f\"affiliations: {affiliations}\")\n",
    "    meta_content.append(f\"funders: {datacite_funders(doc)}\")\n",
    "    meta_content.append(\"---\")\n",
    "    return '\\n'.join(meta_content)\n",
    "\n",
    "def datacite_md(doc):\n",
    "    md = datacite_meta(doc)\n",
    "    \n",
    "    abstract = next((i['description'] for i in doc['attributes']['descriptions'] if i['descriptionType'] == 'Abstract'), None)\n",
    "    if abstract:\n",
    "        md+= '\\n\\n# Abstract'\n",
    "        md+= f'\\n{abstract}'\n",
    "    other_descriptions = [i for i in doc['attributes']['descriptions'] if i['descriptionType'] != 'Abstract']\n",
    "    if other_descriptions:\n",
    "        for desc in other_descriptions:\n",
    "            md+= f'\\n\\n## {desc[\"descriptionType\"]}'\n",
    "            md+= f'\\n{desc[\"description\"].lstrip(\"#\").strip()}'\n",
    "\n",
    "    if doc['attributes']['url']:\n",
    "        md+= f'\\n\\n# Access Points\\n{doc[\"attributes\"][\"url\"]}'\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugo Config File\n",
    "There are a number of things that need to be set up in the Hugo configuration file. Most of this has to do with setting up the [taxonomies](https://gohugo.io/content-management/taxonomies/) that we'll be using, which is essentially the key aspect of processing DataCite repository records into their most useful form, providing several simple ways to browse through and find content of interest.\n",
    "\n",
    "You can manage the config file however you want. I've provided one option here consisting of a site_config dictionary object that you can tweak here in the notebook and then dump to YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WROTE CONFIG FILE\n"
     ]
    }
   ],
   "source": [
    "# Set this parameter based on where you are deploying the site\n",
    "# Note that testing locally with hugo server will \"ignore\" this parameter\n",
    "# (other than the subdomain) and use localhost:1313 (or whatever port you specify)\n",
    "base_url = 'https://datapurifier.github.io/landingpage-in-a-box/'\n",
    "\n",
    "site_config = {\n",
    "    'baseURL': base_url,\n",
    "    'languageCode': 'en-us',\n",
    "    'title': 'Landingpage-in-a-Box',\n",
    "    'theme': 'PaperMod',\n",
    "    'taxonomies': {\n",
    "        'category': 'categories',\n",
    "        'tag': 'tags',\n",
    "        'publishers': 'publishers',\n",
    "        'author': 'author',\n",
    "        'affiliations': 'affiliations'\n",
    "    },\n",
    "    'params': {\n",
    "        'profileMode': {\n",
    "            'enabled': True,\n",
    "            'title': 'Landingpage-in-a-Box',\n",
    "            'subtitle': 'A lightweight approach to a metadata-driven dataset landing page web site',\n",
    "            'buttons': [\n",
    "                {\n",
    "                    'name': 'Search', \n",
    "                    'url': 'search'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Tags',\n",
    "                    'url': 'tags'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Categories', \n",
    "                    'url': 'categories'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Authors', \n",
    "                    'url': 'author'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Affiliations', \n",
    "                    'url': 'affiliations'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Publishers', \n",
    "                    'url': 'publishers'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'ShowRssButtonInSectionTermList': True,\n",
    "    'outputs': {\n",
    "        'home': [\n",
    "            'HTML', \n",
    "            'RSS', \n",
    "            'JSON'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "write_config(site_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get DataCite Items\n",
    "This part of the process is really up to the individual use case. Any type of process is perfectly fine here as long as it returns some set of items in DataCite's native JSON format. This could also be retuned to work with JSON-LD or any other output format desired. The predominant use case is likely to work through a set of items from one or more DataCite repositories (DOI prefixes) that do not otherwise have landing pages in some primary source repository. But this can also be used to spin up some particular context of assets that need to be presented in a particular way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCite DOCUMENTS: 100\n"
     ]
    }
   ],
   "source": [
    "datacite_api = \"https://api.datacite.org/dois?prefix=10.5066&page[size]=100\"\n",
    "items = requests.get(datacite_api).json()\n",
    "print(\"DataCite DOCUMENTS:\", len(items['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataCite Repository Sections\n",
    "We want the DOI prefixes in our collection from DataCite to act as sections within the Hugo site. This means setting up root folders within /content/ for each DOI prefix in our recordset returned from the DataCite API. We'll them write markdown files to these with the remainder of the DOI identifier to provide logical paths at the root of our site that match the DOI. We also write _index.md files into each DOI prefix folder so that it is treated as a section in Hugo's architecture. This will also provide a listing of items at that path depending on the template used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.5066\n"
     ]
    }
   ],
   "source": [
    "build_sections(datacite_repositories(items['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Taxonomy\n",
    "The taxonomies create the navigational structure for the site. They are entirely dependent on how we process DataCite metadata and what we build from that into each content item for the site.\n",
    "\n",
    "Two taxonomies are already established - categories and tags. We place resourceTypeGeneral values into category (e.g., dataset, model, etc.). We place all \"non-parsed\" subjects into tags. In practice, very few DataCite records take advantage of the ability to provide URI values for individual terms or subject scheme information that will break up tags into logical taxonomies. So, this ends up being the majority of the work - using the content as provided and getting it validated and organized into better groupings.\n",
    "\n",
    "We also have several parts of the DataCite schema that logically break out into taxonomies:\n",
    "- authors - DataCite requires at least one \"creator,\" which we often put under the term \"author\" in common practice. This can be reconfigured based on preference. Additional contributors can also be organized from source.\n",
    "- affiliations - Creator affiliations can be broken out and included in their own taxonomy.\n",
    "- publishers - The publisher field is required in DataCite and will be populated with string values that may need more clarification.\n",
    "- funders - Funding institutions are often included and may incorporate additional details that can be organized into data files for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETUP FOLDER/FILE STRUCTURE FOR: affiliations\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: author\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: funders\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: publishers\n"
     ]
    }
   ],
   "source": [
    "names = ['affiliations', 'author', 'funders', 'publishers']\n",
    "layouts_folder = '../layouts'\n",
    "themes_folder = '../themes/PaperMod/layouts/_default'\n",
    "\n",
    "setup_taxonomy(layouts_folder, themes_folder, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process DataCite Records\n",
    "This part of the code will continue to evolve as I work out details on what all should be placed into the markdown representation of DataCite documents and what all needs to be organized out into useful reference files (data objects in the Hugo site). Each web site document built from a DataCite document will have lists of labels in their metadata that populate the configured taxonomies. Some of these are simple name-only values that have no real further depth. Others labels associated with additional information contained in DataCite metadata (e.g., ORCIDs associated with creators/authors). Some of these can be exploited through additional processing to pull in further information from other sources. We can also process things like lists of unqualified subjects to break them out into more specific taxonomies (e.g., place names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcid_mapping = []\n",
    "for document in items['data']:\n",
    "    doi_prefix = document['id'].split('/')[0]\n",
    "    doi_suffix = document['id'].split('/')[1]\n",
    "    file_path = os.path.join('../content', doi_prefix, doi_suffix + '.md')\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(datacite_md(document))\n",
    "\n",
    "    orcid_mapping = datacite_orcids(document, orcid_mapping)\n",
    "\n",
    "json.dump({'authors': {item[0]: item[1] for item in list(set(orcid_mapping))}}, open('../data/orcid_mapping.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize Additional Data\n",
    "I need to continue working on this piece, but these are the things I'm thinking about:\n",
    "* Tee up all person contact names to include the additional details where provided (ORCID, givenName, familyName, etc.)\n",
    "* Use ORCIDs to pull additional information on people from the ORCID registry\n",
    "* Tee up all organization contact names to include additional details (creator and contributor can include identifiers, funders may also contain identifiers for the organizations and things like grant IDs)\n",
    "* Many organization names are simple labels; for those with resolvable identifiers, we can pull additional details from ROR or elsewhere; we could do some work trying to disambiguate other common names\n",
    "* For subjects with identifiers to source and/or scheme information, I can work through to break these out into their own taxonomies\n",
    "* For subjects without identifiers, we can do some logical grouping based on entity recognition (e.g., place names, organization names, etc.); we could also leverage abstract content in this processing since we are going to be doing text processing anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for document in items['data']:\n",
    "    if document['attributes']['creators']:\n",
    "        for creator in document['attributes']['creators']:\n",
    "            if \"nameIdentifiers\" in creator:\n",
    "                orcid_url = next((i['nameIdentifier'] for i in creator['nameIdentifiers'] if i['nameIdentifierScheme'] == 'ORCID'), None)\n",
    "                if orcid_url:\n",
    "                    if creator['nameType'] == 'Personal':\n",
    "                        if 'givenName' in creator:\n",
    "                            name = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "                        else:\n",
    "                            name = creator['name']\n",
    "                    elif creator['nameType'] == 'Organizational':\n",
    "                        name = creator['name']\n",
    "                    authors.append({\n",
    "                        'title': name,\n",
    "                        'orcid': orcid_url,\n",
    "                        'url': \"/authors/\" + orcid_url.split('/')[-1]\n",
    "                    })\n",
    "unique_authors = list(set(tuple(sorted(author.items())) for author in authors))\n",
    "unique_authors = [dict(author) for author in unique_authors]\n",
    "\n",
    "for author in unique_authors:\n",
    "    orcid = author['orcid'].split('/')[-1]\n",
    "    if not os.path.exists(os.path.join('../content/authors', orcid)):\n",
    "        os.makedirs(os.path.join('../content/authors', orcid))\n",
    "    file_path = os.path.join('../content/authors', orcid, '_index.md')\n",
    "    yaml_content = \"---\\n\" + yaml.dump(author, default_flow_style=False) + \"\\n---\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(yaml_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
