{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works through the process of pulling metadata via the DataCite API and building content for the Hugo site. A more elegant solution might be to simply dump DataCite metadata in its original JSON form (possibly ld_json) and then run everything with templates that read data content. However, I've found that some amount of digesting that content into markdown files with YAML metadata works pretty well and provides some ready options. So, I'm trying not to overload this part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get DataCite Items\n",
    "This part of the process is really up to the individual use case. Any type of process is perfectly fine here as long as it returns some set of items in DataCite's native JSON format. This could also be retuned to work with JSON-LD or any other output format desired. The predominant use case is likely to work through a set of items from one or more DataCite repositories (DOI prefixes) that do not otherwise have landing pages in some primary source repository. But this can also be used to spin up some particular context of assets that need to be presented in a particular way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacite_api = \"https://api.datacite.org/dois?prefix=10.5066&page[size]=100\"\n",
    "items = requests.get(datacite_api).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Eventually, I may need to run this as some type of automated process in a pipeline (e.g., in the GitHub actions to load site content before deploying). The following can be pulled out into a different type of pipeline environment for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datacite_repositories(documents):\n",
    "    repositories = [i['id'].split('/')[0] for i in documents]\n",
    "    return list(set(repositories))\n",
    "\n",
    "def build_sections(repositories, content_path='../content'):\n",
    "    for prefix in repositories:\n",
    "        folder_path = os.path.join(content_path, prefix)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        if not os.path.exists(os.path.join(folder_path, '_index.md')):\n",
    "            with open(os.path.join(folder_path, '_index.md'), 'w') as f:\n",
    "                f.write(f'---\\ntitle: {prefix}\\ndate: {str(datetime.utcnow().isoformat())}\\n---\\n')   \n",
    "\n",
    "def datacite_categories(doc):\n",
    "    categories = [doc['attributes']['types']['resourceTypeGeneral']]\n",
    "    return categories\n",
    "\n",
    "def datacite_tags(doc):\n",
    "    tags = []\n",
    "    for subject in doc['attributes']['subjects']:\n",
    "        if subject['subject']:\n",
    "            if ',' in subject['subject']:\n",
    "                tags.extend([i.strip() for i in subject['subject'].split(',')])\n",
    "            else:\n",
    "                tags.append(subject['subject'])\n",
    "    return tags\n",
    "\n",
    "def datacite_publishers(doc):\n",
    "    publishers = [doc['attributes']['publisher']]\n",
    "    return publishers\n",
    "\n",
    "def datacite_creators(doc):\n",
    "    authors = []\n",
    "    affiliations = []\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        if creator['affiliation']:\n",
    "            affiliations.extend(creator['affiliation'])\n",
    "        name_string = creator['name']\n",
    "        if creator['nameType'] == 'Personal' and 'givenName' in creator and 'familyName' in creator:\n",
    "            name_string = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "        authors.append(name_string)\n",
    "            \n",
    "    return authors, list(set(affiliations))\n",
    "\n",
    "def datacite_funders(doc):\n",
    "    funders = []\n",
    "    for funder in doc['attributes']['fundingReferences']:\n",
    "        if funder['funderName']:\n",
    "            funders.append(funder['funderName'])\n",
    "    return list(set(funders))\n",
    "\n",
    "def datacite_orcids(doc, orcid_mapping=[]):\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        orcid = next((i['nameIdentifier'].split('/')[-1] for i in creator['nameIdentifiers'] if i['nameIdentifierScheme'] == 'ORCID'), None)\n",
    "        if not orcid:\n",
    "            return orcid_mapping\n",
    "\n",
    "        name_string = creator['name']\n",
    "        if creator['nameType'] == 'Personal' and 'givenName' in creator and 'familyName' in creator:\n",
    "            name_string = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "        orcid_mapping.append((name_string, orcid))\n",
    "\n",
    "    return orcid_mapping\n",
    "\n",
    "def datacite_meta(doc):\n",
    "    meta_content = ['---']\n",
    "    title = doc['attributes']['titles'][0]['title']\n",
    "    meta_content.append(f'title: \"{title}\"')\n",
    "    meta_content.append(f\"doi: {doc['id']}\")\n",
    "    meta_content.append(f\"date: {doc['attributes']['updated']}\")\n",
    "    # meta_content.append(f\"date: {doc['attributes']['publicationYear']}\")\n",
    "    meta_content.append(f\"categories: {datacite_categories(doc)}\")\n",
    "    meta_content.append(f\"tags: {datacite_tags(doc)}\")\n",
    "    meta_content.append(f\"publishers: {datacite_publishers(doc)}\")\n",
    "    authors, affiliations = datacite_creators(doc)\n",
    "    if authors:\n",
    "        meta_content.append(f\"author: {authors}\")\n",
    "    if affiliations:\n",
    "        meta_content.append(f\"affiliations: {affiliations}\")\n",
    "    meta_content.append(f\"funders: {datacite_funders(doc)}\")\n",
    "    meta_content.append(\"---\")\n",
    "    return '\\n'.join(meta_content)\n",
    "\n",
    "def datacite_md(doc):\n",
    "    md = datacite_meta(doc)\n",
    "    \n",
    "    abstract = next((i['description'] for i in doc['attributes']['descriptions'] if i['descriptionType'] == 'Abstract'), None)\n",
    "    if abstract:\n",
    "        md+= '\\n\\n# Abstract'\n",
    "        md+= f'\\n{abstract}'\n",
    "    other_descriptions = [i for i in doc['attributes']['descriptions'] if i['descriptionType'] != 'Abstract']\n",
    "    if other_descriptions:\n",
    "        for desc in other_descriptions:\n",
    "            md+= f'\\n\\n## {desc[\"descriptionType\"]}'\n",
    "            md+= f'\\n{desc[\"description\"].lstrip(\"#\").strip()}'\n",
    "\n",
    "    if doc['attributes']['url']:\n",
    "        md+= f'\\n\\n# Access Points\\n{doc[\"attributes\"][\"url\"]}'\n",
    "    \n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataCite Repository Sections\n",
    "We want the DOI prefixes in our collection from DataCite to act as sections within the Hugo site. This means setting up root folders within /content/ for each DOI prefix in our recordset returned from the DataCite API. We'll them write markdown files to these with the remainder of the DOI identifier to provide logical paths at the root of our site that match the DOI. We also write _index.md files into each DOI prefix folder so that it is treated as a section in Hugo's architecture. This will also provide a listing of items at that path depending on the template used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_sections(datacite_repositories(items['data']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['affiliations', 'author', 'funders', 'publishers']\n",
    "layouts_folder = '../layouts'\n",
    "themes_folder = '../themes/PaperMod/layouts/_default'\n",
    "\n",
    "for name in names:\n",
    "    folder_path = os.path.join(layouts_folder, name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    list_copy_path = os.path.join(folder_path, 'list.html')\n",
    "    terms_copy_path = os.path.join(folder_path, 'terms.html')\n",
    "    \n",
    "    list_source_path = os.path.join(themes_folder, 'list.html')\n",
    "    terms_source_path = os.path.join(themes_folder, 'terms.html')\n",
    "    \n",
    "    if not os.path.exists(list_copy_path):\n",
    "        shutil.copy(list_source_path, list_copy_path)\n",
    "    \n",
    "    if not os.path.exists(terms_copy_path):\n",
    "        shutil.copy(terms_source_path, terms_copy_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process DataCite Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcid_mapping = []\n",
    "for document in items['data']:\n",
    "    doi_prefix = document['id'].split('/')[0]\n",
    "    doi_suffix = document['id'].split('/')[1]\n",
    "    file_path = os.path.join('../content', doi_prefix, doi_suffix + '.md')\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(datacite_md(document))\n",
    "\n",
    "    orcid_mapping = datacite_orcids(document, orcid_mapping)\n",
    "\n",
    "json.dump({'authors': {item[0]: item[1] for item in list(set(orcid_mapping))}}, open('../data/orcid_mapping.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = []\n",
    "for document in items['data']:\n",
    "    if document['attributes']['creators']:\n",
    "        for creator in document['attributes']['creators']:\n",
    "            if \"nameIdentifiers\" in creator:\n",
    "                orcid_url = next((i['nameIdentifier'] for i in creator['nameIdentifiers'] if i['nameIdentifierScheme'] == 'ORCID'), None)\n",
    "                if orcid_url:\n",
    "                    if creator['nameType'] == 'Personal':\n",
    "                        if 'givenName' in creator:\n",
    "                            name = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "                        else:\n",
    "                            name = creator['name']\n",
    "                    elif creator['nameType'] == 'Organizational':\n",
    "                        name = creator['name']\n",
    "                    authors.append({\n",
    "                        'title': name,\n",
    "                        'orcid': orcid_url,\n",
    "                        'url': \"/authors/\" + orcid_url.split('/')[-1]\n",
    "                    })\n",
    "unique_authors = list(set(tuple(sorted(author.items())) for author in authors))\n",
    "unique_authors = [dict(author) for author in unique_authors]\n",
    "\n",
    "for author in unique_authors:\n",
    "    orcid = author['orcid'].split('/')[-1]\n",
    "    if not os.path.exists(os.path.join('../content/authors', orcid)):\n",
    "        os.makedirs(os.path.join('../content/authors', orcid))\n",
    "    file_path = os.path.join('../content/authors', orcid, '_index.md')\n",
    "    yaml_content = \"---\\n\" + yaml.dump(author, default_flow_style=False) + \"\\n---\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(yaml_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
