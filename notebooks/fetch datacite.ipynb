{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook works through the process of pulling metadata via the DataCite API and building content for the Hugo site. A more elegant solution might be to simply dump DataCite metadata in its original JSON form (possibly ld_json) and then run everything with templates that read data content. However, I've found that some amount of digesting that content into markdown files with YAML metadata works pretty well and provides some ready options. So, I'm trying not to overload this part of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from itertools import groupby\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "Eventually, I may need to run this as some type of automated process in a pipeline (e.g., in the GitHub actions to load site content before deploying). The following can be pulled out into a different type of pipeline environment for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup lists\n",
    "\n",
    "# DataCite contributor types with button labels for browse lists\n",
    "contributorType = {\n",
    "    'author': 'Authors',\n",
    "    'ContactPerson': 'Contact Persons', \n",
    "    'DataCollector': 'Data Collectors',\n",
    "    'DataCurator': 'Data Curators',\n",
    "    'DataManager': 'Data Managers',\n",
    "    'Distributor': 'Distibutors',\n",
    "    'Editor': 'Editors',\n",
    "    'HostingInstitution': 'Hosting Institutions',\n",
    "    'Producer': 'Producers',\n",
    "    'ProjectLeader': 'Project Leaders',\n",
    "    'ProjectManager': 'Project Managers', \n",
    "    'ProjectMember': 'Project Members',\n",
    "    'RegistrationAgency': 'Registration Agencies',\n",
    "    'RegistrationAuthority': 'Registration Authorities',\n",
    "    'RelatedPerson': 'Related Persons',\n",
    "    'Researcher': 'Researchers',\n",
    "    'ResearchGroup': 'Research Groups',\n",
    "    'RightsHolder': 'Rights Holders',\n",
    "    'Sponsor': 'Sponsors',\n",
    "    'Supervisor': 'Supervisors',\n",
    "    'WorkPackageLeader': 'Work Package Leaders',\n",
    "    'Other': 'Other Contributors'\n",
    "}\n",
    "\n",
    "# Functions for setting up the Hugo site\n",
    "def write_config(config, config_path='../hugo.yml'):\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.safe_dump(config, f, default_flow_style=False)\n",
    "    print(\"WROTE CONFIG FILE\")\n",
    "\n",
    "def datacite_repositories(documents):\n",
    "    repositories = [i['id'].split('/')[0] for i in documents]\n",
    "    return list(set(repositories))\n",
    "\n",
    "def clear_content_folders(content_path='../content'):\n",
    "    for item in os.listdir(content_path):\n",
    "        item_path = os.path.join(content_path, item)\n",
    "        \n",
    "        if os.path.isdir(item_path):\n",
    "            shutil.rmtree(item_path)\n",
    "\n",
    "def build_sections(repositories, content_path='../content', clear_folders=True):\n",
    "    if clear_folders:\n",
    "        clear_content_folders(content_path)\n",
    "        print(\"CLEARED CONTENT FOLDERS\")\n",
    "\n",
    "    for prefix in repositories:\n",
    "        folder_path = os.path.join(content_path, prefix)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        if not os.path.exists(os.path.join(folder_path, '_index.md')):\n",
    "            with open(os.path.join(folder_path, '_index.md'), 'w') as f:\n",
    "                f.write(f'---\\ntitle: {prefix}\\ndate: {str(datetime.utcnow().isoformat())}\\n---\\n')\n",
    "        print(\"SETUP FOLDER/FILE STRUCTURE FOR:\", prefix)\n",
    "\n",
    "def setup_taxonomy(layouts_folder, themes_folder, names):\n",
    "    for name in names:\n",
    "        folder_path = os.path.join(layouts_folder, name)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        list_copy_path = os.path.join(folder_path, 'list.html')\n",
    "        terms_copy_path = os.path.join(folder_path, 'terms.html')\n",
    "        \n",
    "        list_source_path = os.path.join(themes_folder, 'list.html')\n",
    "        terms_source_path = os.path.join(themes_folder, 'terms.html')\n",
    "        \n",
    "        if not os.path.exists(list_copy_path):\n",
    "            shutil.copy(list_source_path, list_copy_path)\n",
    "        \n",
    "        if not os.path.exists(terms_copy_path):\n",
    "            shutil.copy(terms_source_path, terms_copy_path)\n",
    "        print(\"SETUP FOLDER/FILE STRUCTURE FOR:\", name)\n",
    "\n",
    "# Functions for parsing contacts from creators and contributors\n",
    "def concat_contacts(documents):\n",
    "    contacts = []\n",
    "    for doc in documents:\n",
    "        contacts.extend(doc['attributes']['creators'])\n",
    "        contacts.extend(doc['attributes']['contributors'])\n",
    "    return contacts\n",
    "\n",
    "def contact_label(doc):\n",
    "    if ('givenName' in doc and doc['givenName'] and len(doc['givenName'].strip()) > 0) and ('familyName' in doc and doc['familyName'] and len(doc['familyName'].strip()) > 0):\n",
    "        return f\"{doc['givenName']} {doc['familyName']}\"\n",
    "    else:\n",
    "        return doc['name']\n",
    "\n",
    "def label_contacts(contact_docs):\n",
    "    labeled_contacts = {}\n",
    "    for doc in contact_docs:\n",
    "        labeled_contacts[contact_label(doc)] = doc\n",
    "    return labeled_contacts\n",
    "\n",
    "def contact_taxonomies(labeled_contacts):\n",
    "    contact_taxonomies = {\n",
    "        'author': {k: v for k, v in labeled_contacts.items() if not v.get('contributorType')}\n",
    "    }\n",
    "    contributor_types = set([contact.get('contributorType') for contact in labeled_contacts.values() if contact.get('contributorType')])\n",
    "    for contributor_type in contributor_types:\n",
    "        contact_taxonomies[contributor_type] = {}\n",
    "\n",
    "    for contributor_type in contributor_types:\n",
    "        contributors = {k: v for k, v in labeled_contacts.items() if v.get('contributorType') == contributor_type}\n",
    "        if contributors:\n",
    "            contact_taxonomies[contributor_type] = contributors\n",
    "\n",
    "    return contact_taxonomies\n",
    "\n",
    "# Function for building funder references\n",
    "def datacite_funders(documents):\n",
    "    funding_references = []\n",
    "    for document in documents:\n",
    "        for ref in document['attributes']['fundingReferences']:\n",
    "            ref['doi'] = document['id']\n",
    "            if 'funderIdentifierType' in ref and ref['funderIdentifierType'] == 'ROR':\n",
    "                if  not ref['funderIdentifier'].startswith('http'):\n",
    "                    ref['funderIdentifier'] = f'https://ror.org/{ref[\"funderIdentifier\"]}'\n",
    "                ref['ror'] = ref['funderIdentifier'].split('/')[-1]\n",
    "            if 'ror' in ref:\n",
    "                ref['label'] = f\"{ref['funderName']} ({ref['ror']})\"\n",
    "            else:\n",
    "                ref['label'] = ref['funderName']\n",
    "\n",
    "            funding_references.append(ref)\n",
    "\n",
    "    funders = {}\n",
    "    for funder_label in list(set([i['label'] for i in funding_references])):\n",
    "        funder_awards = [i for i in funding_references if i['label'] == funder_label]\n",
    "        funders[funder_label] = {\n",
    "            'funderIdentifier': next((i['funderIdentifier'] for i in funder_awards if 'funderIdentifier' in i), None),\n",
    "            'funderName': next((i['funderName'] for i in funder_awards if 'funderName' in i), None),\n",
    "            'awards': []\n",
    "        }\n",
    "        for award in funder_awards:\n",
    "            funders[funder_label]['awards'].append({k:v for k,v in award.items() if k == 'doi' or k.startswith('award')})\n",
    "\n",
    "    funder_index = {}\n",
    "    for funder, funder_info in funders.items():\n",
    "        for award in funder_info['awards']:\n",
    "            funder_index[award['doi']] = funder\n",
    "            \n",
    "    return funders, funder_index\n",
    "\n",
    "# Functions for building subject references\n",
    "def collection_tags(documents):\n",
    "    tags = {}\n",
    "    for doc in documents:\n",
    "        if 'subjects' in doc['attributes'] and doc['attributes']['subjects']:\n",
    "            for subject in doc['attributes']['subjects']:\n",
    "                if subject['subject'] not in tags:\n",
    "                    subject_properties = {k:v for k,v in subject.items() if k != 'subject'}\n",
    "                    tags[subject['subject']] = subject_properties\n",
    "    return tags\n",
    "\n",
    "# Functions for building content items from DataCite documents\n",
    "def datacite_categories(doc):\n",
    "    categories = [doc['attributes']['types']['resourceTypeGeneral']]\n",
    "    return categories\n",
    "\n",
    "def datacite_subjects(doc):\n",
    "    tags = [i['subject'] for i in doc['attributes']['subjects'] if 'subjects' in doc['attributes']]\n",
    "    return tags\n",
    "\n",
    "def datacite_publishers(doc):\n",
    "    publishers = [doc['attributes']['publisher']]\n",
    "    return publishers\n",
    "\n",
    "def datacite_contacts(doc):\n",
    "    doc_contacts = {\n",
    "        'author': [],\n",
    "        'affiliations': []\n",
    "    }\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        if creator['affiliation']:\n",
    "            doc_contacts['affiliations'].extend(creator['affiliation'])\n",
    "        doc_contacts['author'].append(contact_label(creator))\n",
    "    \n",
    "    for contributor in doc['attributes']['contributors']:\n",
    "        if 'contributorType' in contributor and contributor['contributorType']:\n",
    "            if contributor['contributorType'] not in doc_contacts:\n",
    "                doc_contacts[contributor['contributorType']] = []\n",
    "            if creator['affiliation']:\n",
    "                doc_contacts['affiliations'].extend(creator['affiliation'])\n",
    "            doc_contacts[contributor['contributorType']].append(contact_label(contributor))\n",
    "\n",
    "    for key in doc_contacts:\n",
    "        doc_contacts[key] = list(set(doc_contacts[key]))\n",
    "\n",
    "    return doc_contacts\n",
    "\n",
    "def datacite_orcids(doc, orcid_mapping=[]):\n",
    "    for creator in doc['attributes']['creators']:\n",
    "        orcid = next((i['nameIdentifier'].split('/')[-1] for i in creator['nameIdentifiers'] if i['nameIdentifierScheme'] == 'ORCID'), None)\n",
    "        if not orcid:\n",
    "            return orcid_mapping\n",
    "\n",
    "        name_string = creator['name']\n",
    "        if creator['nameType'] == 'Personal' and 'givenName' in creator and 'familyName' in creator:\n",
    "            name_string = f\"{creator['givenName']} {creator['familyName']}\"\n",
    "        orcid_mapping.append((name_string, orcid))\n",
    "\n",
    "    return orcid_mapping\n",
    "\n",
    "def datacite_meta(doc):\n",
    "    meta_content = ['---']\n",
    "    # Set the main title\n",
    "    title = next((i['title'] for i in doc['attributes']['titles'] if 'titleType' not in i or not i['titleType']), None)\n",
    "    title = title.replace('\"', \"'\")\n",
    "    meta_content.append(f'title: \"{title}\"')\n",
    "\n",
    "    # Set doi and url identifiers\n",
    "    meta_content.append(f\"doi: {doc['id']}\")\n",
    "    meta_content.append(f\"referralUrl: {doc['attributes']['url']}\")\n",
    "\n",
    "    # Add resourceTypeGeneral as a category\n",
    "    meta_content.append(\"categories:\")\n",
    "    meta_content.append(f\"- {doc['attributes']['types']['resourceTypeGeneral']}\")\n",
    "\n",
    "    # Add subjects as tags\n",
    "    subjects = list(set([i['subject'] for i in doc['attributes']['subjects'] if 'subjects' in doc['attributes']]))\n",
    "    if subjects:\n",
    "        meta_content.append(\"tags:\")\n",
    "        for term in subjects:\n",
    "            meta_content.append(f\"- {term}\")\n",
    "\n",
    "    # Add publishers to the meta content\n",
    "    meta_content.append(\"publishers:\")\n",
    "    meta_content.append(f\"- {doc['attributes']['publisher']}\")\n",
    "\n",
    "    # Pull creators as authors and affiliations from the creators data structure\n",
    "    meta_content.append(\"author:\")\n",
    "    for item in doc['attributes']['creators']:\n",
    "        meta_content.append(f\"- {item['name']}\")\n",
    "\n",
    "    affiliations = []\n",
    "    for c in doc['attributes']['creators']:\n",
    "        if c['affiliation']:\n",
    "            affiliations.extend(c['affiliation'])\n",
    "        affiliations = list(set(affiliations))\n",
    "    if affiliations:\n",
    "        meta_content.append(\"affiliations:\")\n",
    "        for affiliation in affiliations:\n",
    "            meta_content.append(f\"- {affiliation}\")\n",
    "    \n",
    "    # Pull contributors into their own taxonomies\n",
    "    contributions = {}\n",
    "    for c in doc['attributes']['contributors']:\n",
    "        if c['contributorType'] not in contributions:\n",
    "            contributions[c['contributorType']] = [c['name']]\n",
    "        else:\n",
    "            contributions[c['contributorType']].append(c['name'])\n",
    "    if contributions:\n",
    "        for contributor_type, contributors in contributions.items():\n",
    "            meta_content.append(f\"{contributor_type.lower()}:\")\n",
    "            for contributor in contributors:\n",
    "                meta_content.append(f\"- {contributor}\")\n",
    "\n",
    "    # Add funder labels\n",
    "    if doc['attributes']['fundingReferences']:\n",
    "        meta_content.append(\"funders:\")\n",
    "        for funder_name in list(set([i['funderName'] for i in doc['attributes']['fundingReferences']])):\n",
    "            meta_content.append(f\"- {funder_name}\")\n",
    "\n",
    "    meta_content.append(\"---\")\n",
    "    return '\\n'.join(meta_content)\n",
    "\n",
    "def datacite_md(doc, dois_in_dataset):\n",
    "    md = datacite_meta(doc)\n",
    "    \n",
    "    abstract = next((i['description'] for i in doc['attributes']['descriptions'] if i['descriptionType'] == 'Abstract'), None)\n",
    "    if abstract:\n",
    "        md+= '\\n\\n# Abstract'\n",
    "        md+= f'\\n{abstract}'\n",
    "    other_descriptions = [i for i in doc['attributes']['descriptions'] if i['descriptionType'] != 'Abstract']\n",
    "    if other_descriptions:\n",
    "        for desc in other_descriptions:\n",
    "            md+= f'\\n\\n## {desc[\"descriptionType\"]}'\n",
    "            md+= f'\\n{desc[\"description\"].lstrip(\"#\").strip()}'\n",
    "\n",
    "    if doc['attributes']['url']:\n",
    "        md+= f'\\n\\n# Access Points\\n{doc[\"attributes\"][\"url\"]}'\n",
    "\n",
    "    if doc['attributes']['relatedIdentifiers']:\n",
    "        md+= '\\n\\n# Related Identifiers'\n",
    "        relatedIdentifiers = doc['attributes']['relatedIdentifiers']\n",
    "        relatedIdentifiers.sort(key=lambda x: x['relationType'])\n",
    "        for rel, links in groupby(relatedIdentifiers, lambda x: x['relationType']):\n",
    "            md+=f\"\\n## {rel}\"\n",
    "            for item in links:\n",
    "                if item['relatedIdentifierType'] == 'DOI':\n",
    "                    related_doi = '/'.join(item['relatedIdentifier'].split('/')[-2:])\n",
    "                    if related_doi in dois_in_dataset:\n",
    "                        md+=f\"\\n- [{related_doi}](../../{related_doi}/)\"\n",
    "                    else:\n",
    "                        md+=f\"\\n- https://doi.org/{related_doi}\"\n",
    "                elif item['relatedIdentifierType'] == 'ISBN':\n",
    "                    md+=f\"\\n- http://www.worldcat.org/isbn/{item['relatedIdentifier']}\"\n",
    "                elif item['relatedIdentifierType'] == 'URL':\n",
    "                    md+=f\"\\n- {item['relatedIdentifier']}\"\n",
    "                elif item['relatedIdentifierType'] == 'ISSN':\n",
    "                    md+=f\"\\n- https://portal.issn.org/resource/ISSN/{item['relatedIdentifier']}\"\n",
    "                elif item['relatedIdentifierType'] == 'arXiv':\n",
    "                    md+=f\"\\n- https://arxiv.org/abs/{item['relatedIdentifier'].split(':')[-1]}\"\n",
    "                else:\n",
    "                    md+=f\"\\n- {item['relatedIdentifier']} ({item['relatedIdentifierType']})\"\n",
    "\n",
    "    return md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get DataCite Items\n",
    "This part of the process is really up to the individual use case. Any type of process is perfectly fine here as long as it returns some set of items in DataCite's native JSON format. This could also be retuned to work with JSON-LD or any other output format desired. The predominant use case is likely to work through a set of items from one or more DataCite repositories (DOI prefixes) that do not otherwise have landing pages in some primary source repository. But this can also be used to spin up some particular context of assets that need to be presented in a particular way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCite DOCUMENTS: 100\n"
     ]
    }
   ],
   "source": [
    "datacite_api = 'https://api.datacite.org/dois?query=fundingReferences.funderName:\"National Science Foundation\"&page[size]=100'\n",
    "items = requests.get(datacite_api).json()\n",
    "print(\"DataCite DOCUMENTS:\", len(items['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEARED CONTENT FOLDERS\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.5281\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.3886\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.5061\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.1594\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.15146\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.18128\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.7923\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.34726\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.17632\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.6078\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.48443\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.6076\n",
      "SETUP FOLDER/FILE STRUCTURE FOR: 10.7291\n",
      "WROTE ../content/10.5281/zenodo.10099732.md\n",
      "WROTE ../content/10.5281/zenodo.10099731.md\n",
      "WROTE ../content/10.5281/zenodo.10223759.md\n",
      "WROTE ../content/10.5061/dryad.gqnk98sv9.md\n",
      "WROTE ../content/10.5281/zenodo.8031759.md\n",
      "WROTE ../content/10.5281/zenodo.8031760.md\n",
      "WROTE ../content/10.5061/dryad.m905qfv4v.md\n",
      "WROTE ../content/10.5281/zenodo.10158072.md\n",
      "WROTE ../content/10.5281/zenodo.10158073.md\n",
      "WROTE ../content/10.5061/dryad.7wm37pvzv.md\n",
      "WROTE ../content/10.5061/dryad.mkkwh7143.md\n",
      "WROTE ../content/10.7923/hysd-x388.md\n",
      "WROTE ../content/10.5281/zenodo.10180280.md\n",
      "WROTE ../content/10.5281/zenodo.10045554.md\n",
      "WROTE ../content/10.5281/zenodo.10045555.md\n",
      "WROTE ../content/10.6076/d1cp4r.md\n",
      "WROTE ../content/10.7923/jk5q-6876.md\n",
      "WROTE ../content/10.5281/zenodo.10215234.md\n",
      "WROTE ../content/10.5281/zenodo.10215247.md\n",
      "WROTE ../content/10.18128/d010.v13.0.md\n",
      "WROTE ../content/10.5061/dryad.v6wwpzh2b.md\n",
      "WROTE ../content/10.5061/dryad.q573n5tq2.md\n",
      "WROTE ../content/10.5061/dryad.1jwstqk11.md\n",
      "WROTE ../content/10.6078/d1qf08.md\n",
      "WROTE ../content/10.1594/pangaea.940553.md\n",
      "WROTE ../content/10.5061/dryad.bk3j9kd8t.md\n",
      "WROTE ../content/10.48443/ghry-qw46.md\n",
      "WROTE ../content/10.48443/10dn-8031.md\n",
      "WROTE ../content/10.48443/xmbe-7b55.md\n",
      "WROTE ../content/10.5281/zenodo.10215207.md\n",
      "WROTE ../content/10.5281/zenodo.10215208.md\n",
      "WROTE ../content/10.5061/dryad.wpzgmsbtj.md\n",
      "WROTE ../content/10.5281/zenodo.10210959.md\n",
      "WROTE ../content/10.5281/zenodo.10210958.md\n",
      "WROTE ../content/10.3886/icpsr37320.md\n",
      "WROTE ../content/10.3886/icpsr37320.v4.md\n",
      "WROTE ../content/10.3886/icpsr37320.v3.md\n",
      "WROTE ../content/10.5281/zenodo.10214334.md\n",
      "WROTE ../content/10.5281/zenodo.10214333.md\n",
      "WROTE ../content/10.5061/dryad.xksn02vn0.md\n",
      "WROTE ../content/10.5061/dryad.5mkkwh7bp.md\n",
      "WROTE ../content/10.15146/5xcp-0d46.md\n",
      "WROTE ../content/10.5061/dryad.2256f38.md\n",
      "WROTE ../content/10.5061/dryad.sqv9s4n7n.md\n",
      "WROTE ../content/10.5061/dryad.c866t1gdc.md\n",
      "WROTE ../content/10.5061/dryad.k98sf7mdg.md\n",
      "WROTE ../content/10.5061/dryad.9ghx3ffpp.md\n",
      "WROTE ../content/10.5281/zenodo.10211497.md\n",
      "WROTE ../content/10.5281/zenodo.10211498.md\n",
      "WROTE ../content/10.5061/dryad.98sf7m0nm.md\n",
      "WROTE ../content/10.17632/zpmjwkcnrz.1.md\n",
      "WROTE ../content/10.17632/zpmjwkcnrz.md\n",
      "WROTE ../content/10.5061/dryad.1jwstqk1x.md\n",
      "WROTE ../content/10.5281/zenodo.10160564.md\n",
      "WROTE ../content/10.5281/zenodo.10160563.md\n",
      "WROTE ../content/10.7291/d1vq3r.md\n",
      "WROTE ../content/10.34726/2101.md\n",
      "WROTE ../content/10.5281/zenodo.10210937.md\n",
      "WROTE ../content/10.5281/zenodo.10210936.md\n",
      "WROTE ../content/10.5281/zenodo.10210938.md\n",
      "WROTE ../content/10.5281/zenodo.10210939.md\n",
      "WROTE ../content/10.5281/zenodo.10210946.md\n",
      "WROTE ../content/10.5281/zenodo.10210947.md\n",
      "WROTE ../content/10.5281/zenodo.10210948.md\n",
      "WROTE ../content/10.5281/zenodo.10210949.md\n",
      "WROTE ../content/10.5281/zenodo.10210951.md\n",
      "WROTE ../content/10.5281/zenodo.10210950.md\n",
      "WROTE ../content/10.5281/zenodo.10210952.md\n",
      "WROTE ../content/10.5281/zenodo.10210953.md\n",
      "WROTE ../content/10.5281/zenodo.10210954.md\n",
      "WROTE ../content/10.5281/zenodo.10210955.md\n",
      "WROTE ../content/10.5281/zenodo.10210957.md\n",
      "WROTE ../content/10.5281/zenodo.10210956.md\n",
      "WROTE ../content/10.5281/zenodo.10211031.md\n",
      "WROTE ../content/10.5281/zenodo.10211030.md\n",
      "WROTE ../content/10.5281/zenodo.10210984.md\n",
      "WROTE ../content/10.5281/zenodo.10211018.md\n",
      "WROTE ../content/10.5281/zenodo.10211019.md\n",
      "WROTE ../content/10.5281/zenodo.10211006.md\n",
      "WROTE ../content/10.5281/zenodo.10211007.md\n",
      "WROTE ../content/10.5281/zenodo.10210985.md\n",
      "WROTE ../content/10.5281/zenodo.10210977.md\n",
      "WROTE ../content/10.5281/zenodo.10210978.md\n",
      "WROTE ../content/10.5281/zenodo.10210975.md\n",
      "WROTE ../content/10.5281/zenodo.10210974.md\n",
      "WROTE ../content/10.5281/zenodo.10210969.md\n",
      "WROTE ../content/10.5281/zenodo.10210970.md\n",
      "WROTE ../content/10.5281/zenodo.10210965.md\n",
      "WROTE ../content/10.5281/zenodo.10210966.md\n",
      "WROTE ../content/10.5281/zenodo.10210963.md\n",
      "WROTE ../content/10.5281/zenodo.10210964.md\n",
      "WROTE ../content/10.5281/zenodo.10210961.md\n",
      "WROTE ../content/10.5281/zenodo.10210962.md\n",
      "WROTE ../content/10.5061/dryad.dfn2z355r.md\n",
      "WROTE ../content/10.5281/zenodo.10210681.md\n",
      "WROTE ../content/10.5281/zenodo.10210682.md\n",
      "WROTE ../content/10.5281/zenodo.10210692.md\n",
      "WROTE ../content/10.5281/zenodo.10210691.md\n",
      "WROTE ../content/10.5281/zenodo.10210688.md\n",
      "WROTE ../content/10.5281/zenodo.10210687.md\n"
     ]
    }
   ],
   "source": [
    "dois_in_dataset = [i['id'] for i in items['data']]\n",
    "\n",
    "# Flush previous contents and build folder structure for DOI prefixes\n",
    "build_sections(datacite_repositories(items['data']))\n",
    "\n",
    "# Process documents to produce MD files with metadata\n",
    "for document in items['data']:\n",
    "    doi_prefix = document['id'].split('/')[0]\n",
    "    doi_suffix = document['id'].split('/')[1]\n",
    "    file_path = os.path.join('../content', doi_prefix, doi_suffix + '.md')\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(datacite_md(document, dois_in_dataset))\n",
    "        print(\"WROTE\", file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 41 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   doi                 100 non-null    object\n",
      " 1   identifiers         100 non-null    object\n",
      " 2   creators            100 non-null    object\n",
      " 3   titles              100 non-null    object\n",
      " 4   publisher           100 non-null    object\n",
      " 5   container           100 non-null    object\n",
      " 6   publicationYear     100 non-null    int64 \n",
      " 7   subjects            100 non-null    object\n",
      " 8   contributors        100 non-null    object\n",
      " 9   dates               100 non-null    object\n",
      " 10  language            44 non-null     object\n",
      " 11  types               100 non-null    object\n",
      " 12  relatedIdentifiers  100 non-null    object\n",
      " 13  relatedItems        100 non-null    object\n",
      " 14  sizes               100 non-null    object\n",
      " 15  formats             100 non-null    object\n",
      " 16  version             36 non-null     object\n",
      " 17  rightsList          100 non-null    object\n",
      " 18  descriptions        100 non-null    object\n",
      " 19  geoLocations        100 non-null    object\n",
      " 20  fundingReferences   100 non-null    object\n",
      " 21  url                 100 non-null    object\n",
      " 22  contentUrl          0 non-null      object\n",
      " 23  metadataVersion     100 non-null    int64 \n",
      " 24  schemaVersion       100 non-null    object\n",
      " 25  source              100 non-null    object\n",
      " 26  isActive            100 non-null    bool  \n",
      " 27  state               100 non-null    object\n",
      " 28  reason              0 non-null      object\n",
      " 29  viewCount           100 non-null    int64 \n",
      " 30  downloadCount       100 non-null    int64 \n",
      " 31  referenceCount      100 non-null    int64 \n",
      " 32  citationCount       100 non-null    int64 \n",
      " 33  partCount           100 non-null    int64 \n",
      " 34  partOfCount         100 non-null    int64 \n",
      " 35  versionCount        100 non-null    int64 \n",
      " 36  versionOfCount      100 non-null    int64 \n",
      " 37  created             100 non-null    object\n",
      " 38  registered          100 non-null    object\n",
      " 39  published           0 non-null      object\n",
      " 40  updated             100 non-null    object\n",
      "dtypes: bool(1), int64(10), object(30)\n",
      "memory usage: 31.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_items = pd.DataFrame([i['attributes'] for i in items['data']])\n",
    "# df_items = df_items.convert_dtypes()\n",
    "df_items.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Items\n",
    "I need to come back to examine more we can do on related items. One thought is to pull the relationships where the target object is found within the dataset being used to build the site and then showing an interactive graph for users to use in navigating the relationships inherent in the particular site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_related_id = df_items[df_items['relatedIdentifiers'].str.len() > 0][['doi','relatedIdentifiers']].explode('relatedIdentifiers')\n",
    "df_related_id = pd.concat([df_related_id.drop(['relatedIdentifiers'], axis=1), df_related_id['relatedIdentifiers'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize Creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_creators = df_items[df_items['creators'].str.len() > 0][['doi','creators']].explode('creators')\n",
    "df_creators = pd.concat([df_creators.drop(['creators'], axis=1), df_creators['creators'].apply(pd.Series)], axis=1)\n",
    "df_creators['contributorType'] = 'author'\n",
    "\n",
    "df_contributors = df_items[df_items['contributors'].str.len() > 0][['doi','contributors']].explode('contributors')\n",
    "df_contributors = pd.concat([df_contributors.drop(['contributors'], axis=1), df_contributors['contributors'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df_contacts = pd.concat([df_creators, df_contributors])\n",
    "\n",
    "df_contacts['orcid'] = df_contacts['nameIdentifiers'].apply(lambda x: next((i['nameIdentifier'].split('/')[-1] for i in x if i['nameIdentifierScheme'] == 'ORCID'), ''))\n",
    "df_contacts['ror'] = df_contacts['nameIdentifiers'].apply(lambda x: next((i['nameIdentifier'].split('/')[-1] for i in x if i['nameIdentifierScheme'] == 'ROR'), ''))\n",
    "\n",
    "def contact_url(row):\n",
    "    if len(row['orcid']) > 0:\n",
    "        return f'https://orcid.org/{row[\"orcid\"]}'\n",
    "    if len(row['ror']) > 0:\n",
    "        return f'https://ror.org/{row[\"ror\"]}'\n",
    "    return ''\n",
    "\n",
    "df_contacts['url'] = df_contacts.apply(lambda x: contact_url(x), axis=1)\n",
    "df_contacts['affiliation_string'] = df_contacts['affiliation'].apply(lambda x: '; '.join(x) if x else '')\n",
    "df_contacts['doi_contact'] = df_contacts.apply(lambda x: {'name': x['name'], 'orcid': x['orcid'], 'ror': x['ror'], 'affiliation': x['affiliation_string']}, axis=1)\n",
    "\n",
    "# Package contact information for doi cache\n",
    "grouped_contacts = df_contacts[['doi','contributorType','doi_contact']].groupby(['doi','contributorType'], as_index=False).agg(list)\n",
    "grouped_contacts = grouped_contacts.groupby('doi').apply(lambda x: x.set_index('contributorType')['doi_contact'].to_dict()).reset_index(name='contacts')\n",
    "\n",
    "df_geo = df_items[df_items['geoLocations'].str.len() > 0][['doi','geoLocations']].explode('geoLocations')\n",
    "df_geo = pd.concat([df_geo.drop(['geoLocations'], axis=1), df_geo['geoLocations'].apply(pd.Series)], axis=1)\n",
    "df_geo['bbox'] = df_geo['geoLocationBox'].apply(lambda x: [[x['southBoundLatitude'], x['westBoundLongitude']], [x['northBoundLatitude'], x['eastBoundLongitude']]] if isinstance(x, dict) else None)\n",
    "df_geo['point'] = df_geo['geoLocationPoint'].apply(lambda x: [x['pointLatitude'], x['pointLongitude']] if isinstance(x, dict) else None)\n",
    "\n",
    "df_maps = pd.concat([\n",
    "    df_geo[df_geo['point'].notnull()].groupby('doi')['point'].agg(list),\n",
    "    df_geo[df_geo['bbox'].notnull()].groupby('doi')['bbox'].first()\n",
    "], axis=1).reset_index('doi')\n",
    "\n",
    "datacite_core_props = [\n",
    "    'doi',\n",
    "    'publisher',\n",
    "    'publicationYear',\n",
    "    'contentUrl'\n",
    "]\n",
    "\n",
    "doi_data_file = pd.merge(\n",
    "    left=df_items[datacite_core_props],\n",
    "    right=grouped_contacts,\n",
    "    how='left',\n",
    "    on='doi'\n",
    ")\n",
    "\n",
    "doi_data_file = pd.merge(\n",
    "    left=doi_data_file,\n",
    "    right=df_maps,\n",
    "    how='left',\n",
    "    on='doi'\n",
    ").fillna('')\n",
    "\n",
    "json.dump(doi_data_file.set_index('doi').to_dict('index'), open('../data/doi.json', 'w'), indent=2)\n",
    "\n",
    "# Package contact information for the contacts cache\n",
    "contacts_core = df_contacts[['name','nameType','givenName','familyName','orcid','ror','url']].groupby('name', as_index=False).first()\n",
    "contact_affiliations = df_contacts[df_contacts['affiliation'].str.len() > 0][['name','affiliation']].explode('affiliation').groupby('name', as_index=False).agg(list)\n",
    "contact_affiliations['affiliation'] = contact_affiliations['affiliation'].apply(lambda x: list(set(x)))\n",
    "contact_contributions = df_contacts[['name','contributorType']].groupby('name', as_index=False).agg(list)\n",
    "contact_contributions['contributorType'] = contact_contributions['contributorType'].apply(lambda x: list(set(x)))\n",
    "\n",
    "contact_reference = pd.merge(\n",
    "    left=contacts_core,\n",
    "    right=contact_affiliations,\n",
    "    how='left',\n",
    "    on='name'\n",
    ") \n",
    "contact_reference = pd.merge(\n",
    "    left=contact_reference,\n",
    "    right=contact_contributions,\n",
    "    how='left',\n",
    "    on='name'\n",
    ").fillna('')\n",
    "\n",
    "json.dump(contact_reference.set_index('name').to_dict('index'), open('../data/contacts.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexes\n",
    "We can create what are essentially a series of local indexes from the original DataCite metadata cached in the /data/ folder for later reference from template files. Given the title of a page or a value in that page's metadata, we can retrieve additional data from the cache. Setting the index to the value of the label makes this efficient and straightforward.\n",
    "\n",
    "### Full record on DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_datacite(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = df_items[['doi','titles']].explode('titles')\n",
    "df_titles = pd.concat([df_titles.drop(['titles'], axis=1), df_titles['titles'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df_descriptions = df_items[['doi','descriptions']].explode('descriptions')\n",
    "df_descriptions = pd.concat([df_descriptions.drop(['descriptions'], axis=1), df_descriptions['descriptions'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_title_lookup = df_titles[df_titles['titleType'].isnull()].set_index('doi')['title'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_items.iterrows():\n",
    "    md_elements = ['---']\n",
    "    md_elements.append(f\"doi: {row['doi']}\")\n",
    "    md_elements.append(f\"publicationYear: [{row['publicationYear']}]\")\n",
    "    title = main_title_lookup[row[\"doi\"]].replace('\"',\"'\")\n",
    "    md_elements.append(f'title: \"{title}\"')\n",
    "    md_elements.append(f\"categories: {[row['types']['resourceTypeGeneral']]}\")\n",
    "    md_elements.append(f\"tags: {[i['subject'] for i in row['subjects']]}\")\n",
    "    md_elements.append(f\"publishers: {[row['publisher']]}\")\n",
    "\n",
    "    item_contacts = contact_lookup[contact_lookup['doi'] == row['doi']]\n",
    "    if not item_contacts.empty:\n",
    "        for i, c in item_contacts.iterrows():\n",
    "            md_elements.append(f\"{c['contributorType']}: {c['label']}\")\n",
    "\n",
    "    md_elements.append('---')\n",
    "\n",
    "    abstract = next((i['description'] for i in row['descriptions'] if i['descriptionType'] == 'Abstract'), None)\n",
    "\n",
    "    display(md_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_creators = df_items[df_items['creators'].str.len() > 0][['doi','creators']].explode('creators')\n",
    "df_creators = pd.concat([df_creators.drop(['creators'], axis=1), df_creators['creators'].apply(pd.Series)], axis=1)\n",
    "df_creators['contributorType'] = 'author'\n",
    "\n",
    "df_contributors = df_items[df_items['contributors'].str.len() > 0][['doi','contributors']].explode('contributors')\n",
    "df_contributors = pd.concat([df_contributors.drop(['contributors'], axis=1), df_contributors['contributors'].apply(pd.Series)], axis=1)\n",
    "\n",
    "df_contacts = pd.concat([df_creators, df_contributors]).reset_index(drop=True)\n",
    "df_contacts['orcid'] = df_contacts['nameIdentifiers'].apply(lambda x: next((i['nameIdentifier'].split('/')[-1] for i in x if i['nameIdentifierScheme'] == 'ORCID'), ''))\n",
    "df_contacts['ror'] = df_contacts['nameIdentifiers'].apply(lambda x: next((i['nameIdentifier'].split('/')[-1] for i in x if i['nameIdentifierScheme'] == 'ROR'), ''))\n",
    "\n",
    "def contact_url(contact):\n",
    "    if contact['orcid']:\n",
    "        return f'https://orcid.org/{contact[\"orcid\"]}'\n",
    "    elif contact['ror']:\n",
    "        return f'https://ror.org/{contact[\"ror\"]}'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "df_contacts['url'] = df_contacts.apply(contact_url, axis=1)\n",
    "df_contacts.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Choppali Sudarshan, Chetan</td>\n",
       "      <td>Arizona State University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matkar, Nikhil</td>\n",
       "      <td>Arizona State University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vrudhula, Sarma</td>\n",
       "      <td>Arizona State University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sapatnekar, Sachin</td>\n",
       "      <td>University of Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chhabria, Vidya</td>\n",
       "      <td>Arizona State University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Azenon, Jonathan</td>\n",
       "      <td>Cornell College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>Cugley, John</td>\n",
       "      <td>Australian Speleological Federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Woods, David</td>\n",
       "      <td>Queensland Department of Environment and Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Humphreys, William</td>\n",
       "      <td>Western Australian Museum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Barbante, Carlo</td>\n",
       "      <td>Universita Ca Foscari Dipartimento di Scienze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name  \\\n",
       "0     Choppali Sudarshan, Chetan   \n",
       "1                 Matkar, Nikhil   \n",
       "2                Vrudhula, Sarma   \n",
       "3             Sapatnekar, Sachin   \n",
       "4                Chhabria, Vidya   \n",
       "...                          ...   \n",
       "1473            Azenon, Jonathan   \n",
       "1474                Cugley, John   \n",
       "1475                Woods, David   \n",
       "1476          Humphreys, William   \n",
       "1477             Barbante, Carlo   \n",
       "\n",
       "                                            affiliation  \n",
       "0                              Arizona State University  \n",
       "1                              Arizona State University  \n",
       "2                              Arizona State University  \n",
       "3                               University of Minnesota  \n",
       "4                              Arizona State University  \n",
       "...                                                 ...  \n",
       "1473                                    Cornell College  \n",
       "1474                Australian Speleological Federation  \n",
       "1475   Queensland Department of Environment and Science  \n",
       "1476                          Western Australian Museum  \n",
       "1477  Universita Ca Foscari Dipartimento di Scienze ...  \n",
       "\n",
       "[165 rows x 2 columns]"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact_affiliations = df_contacts[df_contacts['affiliation'].str.len() > 0][['name','affiliation']].explode('affiliation').drop_duplicates()\n",
    "contact_affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>affiliation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>Denniston, Rhawn</td>\n",
       "      <td>Cornell College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Azenon, Jonathan</td>\n",
       "      <td>Cornell College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>Cugley, John</td>\n",
       "      <td>Australian Speleological Federation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>Humphreys, William</td>\n",
       "      <td>Western Australian Museum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                          affiliation\n",
       "1466    Denniston, Rhawn                      Cornell College\n",
       "1473    Azenon, Jonathan                      Cornell College\n",
       "1474        Cugley, John  Australian Speleological Federation\n",
       "1476  Humphreys, William            Western Australian Museum"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contact_affiliations[contact_affiliations['affiliation'].isin(df_contacts['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_roles = df_contacts[df_contacts['contributorType'].str.len() > 0][['name','contributorType']].groupby('name', as_index=False).agg(list)\n",
    "contact_roles['roles'] = contact_roles['contributorType'].apply(lambda x: list(set(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>nameType</th>\n",
       "      <th>givenName</th>\n",
       "      <th>familyName</th>\n",
       "      <th>orcid</th>\n",
       "      <th>ror</th>\n",
       "      <th>url</th>\n",
       "      <th>roles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aguilar, Salomón</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Salomón</td>\n",
       "      <td>Aguilar</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alvarez-Buylla, Aurora</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Alvarez-Buylla</td>\n",
       "      <td>0000-0001-6256-0300</td>\n",
       "      <td></td>\n",
       "      <td>https://orcid.org/0000-0001-6256-0300</td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An, Sizhe</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Sizhe</td>\n",
       "      <td>An</td>\n",
       "      <td>0000-0002-9211-4886</td>\n",
       "      <td></td>\n",
       "      <td>https://orcid.org/0000-0002-9211-4886</td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angela, Mercia</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Mercia</td>\n",
       "      <td>Angela</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anh Thu Nguyen</td>\n",
       "      <td>Personal</td>\n",
       "      <td></td>\n",
       "      <td>Anh Thu Nguyen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Woods, David</td>\n",
       "      <td>Personal</td>\n",
       "      <td>David</td>\n",
       "      <td>Woods</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Woodson, C. Brock</td>\n",
       "      <td>Personal</td>\n",
       "      <td>C. Brock</td>\n",
       "      <td>Woodson</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Yan, Lingfeng</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Lingfeng</td>\n",
       "      <td>Yan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Yardumian, Aram</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Aram</td>\n",
       "      <td>Yardumian</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[DataCollector]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Ye, Jun</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Jun</td>\n",
       "      <td>Ye</td>\n",
       "      <td>0000-0003-0076-2112</td>\n",
       "      <td></td>\n",
       "      <td>https://orcid.org/0000-0003-0076-2112</td>\n",
       "      <td>[author]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name  nameType givenName      familyName  \\\n",
       "0          Aguilar, Salomón  Personal   Salomón         Aguilar   \n",
       "1    Alvarez-Buylla, Aurora  Personal    Aurora  Alvarez-Buylla   \n",
       "2                 An, Sizhe  Personal     Sizhe              An   \n",
       "3            Angela, Mercia  Personal    Mercia          Angela   \n",
       "4            Anh Thu Nguyen  Personal            Anh Thu Nguyen   \n",
       "..                      ...       ...       ...             ...   \n",
       "214            Woods, David  Personal     David           Woods   \n",
       "215       Woodson, C. Brock  Personal  C. Brock         Woodson   \n",
       "216           Yan, Lingfeng  Personal  Lingfeng             Yan   \n",
       "217         Yardumian, Aram  Personal      Aram       Yardumian   \n",
       "218                 Ye, Jun  Personal       Jun              Ye   \n",
       "\n",
       "                   orcid ror                                    url  \\\n",
       "0                                                                     \n",
       "1    0000-0001-6256-0300      https://orcid.org/0000-0001-6256-0300   \n",
       "2    0000-0002-9211-4886      https://orcid.org/0000-0002-9211-4886   \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "..                   ...  ..                                    ...   \n",
       "214                                                                   \n",
       "215                                                                   \n",
       "216                                                                   \n",
       "217                                                                   \n",
       "218  0000-0003-0076-2112      https://orcid.org/0000-0003-0076-2112   \n",
       "\n",
       "               roles  \n",
       "0           [author]  \n",
       "1           [author]  \n",
       "2           [author]  \n",
       "3           [author]  \n",
       "4           [author]  \n",
       "..               ...  \n",
       "214          [Other]  \n",
       "215         [author]  \n",
       "216         [author]  \n",
       "217  [DataCollector]  \n",
       "218         [author]  \n",
       "\n",
       "[219 rows x 8 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(\n",
    "    left=df_contacts.drop(columns=['doi','nameIdentifiers','affiliation','contributorType']).groupby('name', as_index=False).first(),\n",
    "    right=contact_roles[['name','roles']],\n",
    "    how='left',\n",
    "    on='name'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>name</th>\n",
       "      <th>nameType</th>\n",
       "      <th>givenName</th>\n",
       "      <th>familyName</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>nameIdentifiers</th>\n",
       "      <th>contributorType</th>\n",
       "      <th>orcid</th>\n",
       "      <th>ror</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10.48443/ghry-qw46</td>\n",
       "      <td>National Ecological Observatory Network (NEON)</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'schemeUri': 'https://www.re3data.org/', 'na...</td>\n",
       "      <td>author</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10.48443/10dn-8031</td>\n",
       "      <td>National Ecological Observatory Network (NEON)</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'schemeUri': 'https://www.re3data.org/', 'na...</td>\n",
       "      <td>author</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10.48443/xmbe-7b55</td>\n",
       "      <td>National Ecological Observatory Network (NEON)</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'schemeUri': 'https://www.re3data.org/', 'na...</td>\n",
       "      <td>author</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>10.5281/zenodo.10210959</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>10.5281/zenodo.10210958</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>10.5281/zenodo.10210682</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>10.5281/zenodo.10210692</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>10.5281/zenodo.10210691</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>10.5281/zenodo.10210688</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1548</th>\n",
       "      <td>10.5281/zenodo.10210687</td>\n",
       "      <td>International Ocean Discovery Program</td>\n",
       "      <td>Organizational</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>DataCollector</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          doi                                            name  \\\n",
       "106        10.48443/ghry-qw46  National Ecological Observatory Network (NEON)   \n",
       "107        10.48443/10dn-8031  National Ecological Observatory Network (NEON)   \n",
       "108        10.48443/xmbe-7b55  National Ecological Observatory Network (NEON)   \n",
       "1463  10.5281/zenodo.10210959           International Ocean Discovery Program   \n",
       "1464  10.5281/zenodo.10210958           International Ocean Discovery Program   \n",
       "...                       ...                                             ...   \n",
       "1544  10.5281/zenodo.10210682           International Ocean Discovery Program   \n",
       "1545  10.5281/zenodo.10210692           International Ocean Discovery Program   \n",
       "1546  10.5281/zenodo.10210691           International Ocean Discovery Program   \n",
       "1547  10.5281/zenodo.10210688           International Ocean Discovery Program   \n",
       "1548  10.5281/zenodo.10210687           International Ocean Discovery Program   \n",
       "\n",
       "            nameType givenName familyName affiliation  \\\n",
       "106   Organizational                               []   \n",
       "107   Organizational                               []   \n",
       "108   Organizational                               []   \n",
       "1463  Organizational                               []   \n",
       "1464  Organizational                               []   \n",
       "...              ...       ...        ...         ...   \n",
       "1544  Organizational                               []   \n",
       "1545  Organizational                               []   \n",
       "1546  Organizational                               []   \n",
       "1547  Organizational                               []   \n",
       "1548  Organizational                               []   \n",
       "\n",
       "                                        nameIdentifiers contributorType orcid  \\\n",
       "106   [{'schemeUri': 'https://www.re3data.org/', 'na...          author         \n",
       "107   [{'schemeUri': 'https://www.re3data.org/', 'na...          author         \n",
       "108   [{'schemeUri': 'https://www.re3data.org/', 'na...          author         \n",
       "1463                                                 []   DataCollector         \n",
       "1464                                                 []   DataCollector         \n",
       "...                                                 ...             ...   ...   \n",
       "1544                                                 []   DataCollector         \n",
       "1545                                                 []   DataCollector         \n",
       "1546                                                 []   DataCollector         \n",
       "1547                                                 []   DataCollector         \n",
       "1548                                                 []   DataCollector         \n",
       "\n",
       "     ror url  \n",
       "106           \n",
       "107           \n",
       "108           \n",
       "1463          \n",
       "1464          \n",
       "...   ..  ..  \n",
       "1544          \n",
       "1545          \n",
       "1546          \n",
       "1547          \n",
       "1548          \n",
       "\n",
       "[63 rows x 11 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_contacts[\n",
    "    (df_contacts['nameType'] == 'Organizational')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contacts[df_contacts['affiliation'].str.len() > 0][['doi','affiliation']].explode('affiliation').groupby('affiliation').agg(list)['doi'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contacts[df_contacts['doi'] == '10.5061/dryad.c866t1gdc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_lookup = df_contacts[['label','contributorType','doi']].groupby(['doi','contributorType'], as_index=False).agg(list)\n",
    "contact_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funders\n",
    "The main thing we get from looking at funders is a ROR identifier in some cases that helps to disambiguate named organizations. For now, I am dumping a cache of funders indexed to their funderName values that were used when generating the content pages. I include ROR and a URL form for ease of use. I also include a list of awards in the data. These can include further details on award numbers, award titles, and some resolvable identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_funders = df_items[df_items['fundingReferences'].str.len() > 0][['doi','fundingReferences']].explode('fundingReferences')\n",
    "df_funders = pd.concat([df_funders.drop(['fundingReferences'], axis=1), df_funders['fundingReferences'].apply(pd.Series)], axis=1)\n",
    "df_funders['ror'] = df_funders.apply(lambda x: x['funderIdentifier'].split('/')[-1] if x['funderIdentifierType'] == 'ROR' else None, axis=1)\n",
    "df_funders['url'] = df_funders['ror'].apply(lambda x: f'https://ror.org/{x}' if x else None)\n",
    "\n",
    "def award(row):\n",
    "    award = {\n",
    "        'doi': row['doi']\n",
    "    }\n",
    "    for key in row.keys():\n",
    "        if key.startswith('award'):\n",
    "            award[key] = row[key] if isinstance(row[key], str) else ''\n",
    "    return award\n",
    "\n",
    "df_funders['award'] = df_funders.apply(award, axis=1)\n",
    "\n",
    "grouped_df = df_funders.groupby('funderName').agg({'award': lambda x: x.tolist(), 'ror': 'first', 'url': 'first'}).reset_index()\n",
    "\n",
    "output_dict = {}\n",
    "for _, row in grouped_df.iterrows():\n",
    "    output_dict[row['funderName']] = {\n",
    "        'award': row['award'],\n",
    "        'ror': row['ror'],\n",
    "        'url': row['url']\n",
    "    }\n",
    "\n",
    "json.dump(output_dict, open('../data/funders.json', 'w'), indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjects = df_items[df_items['subjects'].str.len() > 0][['doi','subjects']].explode('subjects')\n",
    "df_subjects = pd.concat([df_subjects.drop(['subjects'], axis=1), df_subjects['subjects'].apply(pd.Series)], axis=1)\n",
    "json.dump(df_subjects[['subject','doi']].groupby('subject', as_index=False).agg(list).set_index('subject')['doi'].to_dict(), open('../data/tags.json', 'w'), indent=2)\n",
    "tag_lookup = df_subjects[['subject','doi']].groupby('doi', as_index=False).agg(list).set_index('doi')['subject'].to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break out funders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funders, funder_index = datacite_funders(items['data'])\n",
    "with open('../data/funders.json', 'w') as f:\n",
    "    json.dump(funders, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build out person and organization contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_lookup = contact_taxonomies(label_contacts(concat_contacts(items['data'])))\n",
    "for taxonomy, taxonomy_items in contact_lookup.items():\n",
    "    with open(f'../data/{taxonomy}.json', 'w') as f:\n",
    "        json.dump(taxonomy_items, f, indent=2)\n",
    "contact_lookup.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build DataCite Repository Sections\n",
    "We want the DOI prefixes in our collection from DataCite to act as sections within the Hugo site. This means setting up root folders within /content/ for each DOI prefix in our recordset returned from the DataCite API. We'll them write markdown files to these with the remainder of the DOI identifier to provide logical paths at the root of our site that match the DOI. We also write _index.md files into each DOI prefix folder so that it is treated as a section in Hugo's architecture. This will also provide a listing of items at that path depending on the template used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Taxonomy\n",
    "The taxonomies create the navigational structure for the site. They are entirely dependent on how we process DataCite metadata and what we build from that into each content item for the site.\n",
    "\n",
    "Two taxonomies are already established - categories and tags. We place resourceTypeGeneral values into category (e.g., dataset, model, etc.). We place all \"non-parsed\" subjects into tags. In practice, very few DataCite records take advantage of the ability to provide URI values for individual terms or subject scheme information that will break up tags into logical taxonomies. So, this ends up being the majority of the work - using the content as provided and getting it validated and organized into better groupings.\n",
    "\n",
    "We also have several parts of the DataCite schema that logically break out into taxonomies:\n",
    "- authors - DataCite requires at least one \"creator,\" which we often put under the term \"author\" in common practice. This can be reconfigured based on preference. Additional contributors can also be organized from source.\n",
    "- affiliations - Creator affiliations can be broken out and included in their own taxonomy.\n",
    "- publishers - The publisher field is required in DataCite and will be populated with string values that may need more clarification.\n",
    "- funders - Funding institutions are often included and may incorporate additional details that can be organized into data files for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['affiliations', 'funders', 'publishers']\n",
    "names.extend(contact_lookup.keys())\n",
    "layouts_folder = '../layouts'\n",
    "themes_folder = '../themes/lpiab-theme/layouts/_default'\n",
    "\n",
    "setup_taxonomy(layouts_folder, themes_folder, names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hugo Config File\n",
    "There are a number of things that need to be set up in the Hugo configuration file. Most of this has to do with setting up the [taxonomies](https://gohugo.io/content-management/taxonomies/) that we'll be using, which is essentially the key aspect of processing DataCite repository records into their most useful form, providing several simple ways to browse through and find content of interest.\n",
    "\n",
    "You can manage the config file however you want. I've provided one option here consisting of a site_config dictionary object that you can tweak here in the notebook and then dump to YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this parameter based on where you are deploying the site\n",
    "# Note that testing locally with hugo server will \"ignore\" this parameter\n",
    "# (other than the subdomain) and use localhost:1313 (or whatever port you specify)\n",
    "base_url = 'https://datapurifier.github.io/landingpage-in-a-box/'\n",
    "\n",
    "site_config = {\n",
    "    'baseURL': base_url,\n",
    "    'languageCode': 'en-us',\n",
    "    'title': 'Landingpage-in-a-Box',\n",
    "    'theme': 'lpiab-theme',\n",
    "    'taxonomies': {\n",
    "        'category': 'categories',\n",
    "        'tag': 'tags',\n",
    "        'publishers': 'publishers',\n",
    "        'author': 'author',\n",
    "        'affiliations': 'affiliations',\n",
    "        'funders': 'funders',\n",
    "        'DataCollector': 'DataCollector',\n",
    "        'Other': 'Other', \n",
    "        'HostingInstitution': 'HostingInstitution', \n",
    "        'Sponsor': 'Sponsor'\n",
    "    },\n",
    "    'params': {\n",
    "        'profileMode': {\n",
    "            'enabled': True,\n",
    "            'title': 'Landingpage-in-a-Box',\n",
    "            'subtitle': 'A lightweight approach to a landing page web site built from identifier registry metadata',\n",
    "            'buttons': [\n",
    "                {\n",
    "                    'name': 'Search', \n",
    "                    'url': 'search'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Tags',\n",
    "                    'url': 'tags'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Categories', \n",
    "                    'url': 'categories'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Affiliations', \n",
    "                    'url': 'affiliations'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Publishers', \n",
    "                    'url': 'publishers'\n",
    "                },\n",
    "                {\n",
    "                    'name': 'Funders',\n",
    "                    'url': 'funders'\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    'ShowRssButtonInSectionTermList': True,\n",
    "    'outputs': {\n",
    "        'home': [\n",
    "            'HTML', \n",
    "            'RSS', \n",
    "            'JSON'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "for url, name in contributorType.items():\n",
    "    if url in contact_lookup:\n",
    "        site_config['params']['profileMode']['buttons'].append({'name': name, 'url': url})\n",
    "\n",
    "write_config(site_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process DataCite Records\n",
    "This part of the code will continue to evolve as I work out details on what all should be placed into the markdown representation of DataCite documents and what all needs to be organized out into useful reference files (data objects in the Hugo site). Each web site document built from a DataCite document will have lists of labels in their metadata that populate the configured taxonomies. Some of these are simple name-only values that have no real further depth. Others labels associated with additional information contained in DataCite metadata (e.g., ORCIDs associated with creators/authors). Some of these can be exploited through additional processing to pull in further information from other sources. We can also process things like lists of unqualified subjects to break them out into more specific taxonomies (e.g., place names)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
